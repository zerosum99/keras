{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'win32'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sys.version_info(major=3, minor=7, micro=3, releaselevel='final', serial=0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.version_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  스파크를 인식하기\n",
    "\n",
    "!pip install findspark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 윈도우즈에서 스파크 설치\n",
    "\n",
    "    java 버전을 1.8에 맞춰 jdk 설치할 것 \n",
    "    \n",
    "https://medium.com/@naomi.fridman/install-pyspark-to-run-on-jupyter-notebook-on-windows-4ec2009de21f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\spark\\spark-2.4.4-bin-hadoop2.7\n"
     ]
    }
   ],
   "source": [
    "print(os.environ['SPARK_HOME'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\spark\\\\spark-2.4.4-bin-hadoop2.7'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "import pyspark\n",
    "findspark.find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Create a SparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 스파크 컨텍스트 설명\n",
    "\n",
    "https://godblessyk.tistory.com/m/entry/sparkSparkContext?fbclid=IwAR2nKoUk2Lkn0u68vmtr4NcXlfM59A-WMaZVm-qRnVHrlFoE0S6-1Jz4bKY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "conf = pyspark.SparkConf().setAppName('appName').setMaster('local')\n",
    "sc = pyspark.SparkContext(conf=conf)\n",
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv('./data/titanic.csv', inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "887"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+--------------------+------+----+-----------------------+-----------------------+-------+\n",
      "|Survived|Pclass|                Name|   Sex| Age|Siblings/Spouses Aboard|Parents/Children Aboard|   Fare|\n",
      "+--------+------+--------------------+------+----+-----------------------+-----------------------+-------+\n",
      "|       0|     3|Mr. Owen Harris B...|  male|22.0|                      1|                      0|   7.25|\n",
      "|       1|     1|Mrs. John Bradley...|female|38.0|                      1|                      0|71.2833|\n",
      "|       1|     3|Miss. Laina Heikk...|female|26.0|                      0|                      0|  7.925|\n",
      "|       1|     1|Mrs. Jacques Heat...|female|35.0|                      1|                      0|   53.1|\n",
      "|       0|     3|Mr. William Henry...|  male|35.0|                      0|                      0|   8.05|\n",
      "|       0|     3|     Mr. James Moran|  male|27.0|                      0|                      0| 8.4583|\n",
      "|       0|     1|Mr. Timothy J McC...|  male|54.0|                      0|                      0|51.8625|\n",
      "|       0|     3|Master. Gosta Leo...|  male| 2.0|                      3|                      1| 21.075|\n",
      "|       1|     3|Mrs. Oscar W (Eli...|female|27.0|                      0|                      2|11.1333|\n",
      "|       1|     2|Mrs. Nicholas (Ad...|female|14.0|                      1|                      0|30.0708|\n",
      "|       1|     3|Miss. Marguerite ...|female| 4.0|                      1|                      1|   16.7|\n",
      "|       1|     1|Miss. Elizabeth B...|female|58.0|                      0|                      0|  26.55|\n",
      "|       0|     3|Mr. William Henry...|  male|20.0|                      0|                      0|   8.05|\n",
      "|       0|     3|Mr. Anders Johan ...|  male|39.0|                      1|                      5| 31.275|\n",
      "|       0|     3|Miss. Hulda Amand...|female|14.0|                      0|                      0| 7.8542|\n",
      "|       1|     2|Mrs. (Mary D King...|female|55.0|                      0|                      0|   16.0|\n",
      "|       0|     3| Master. Eugene Rice|  male| 2.0|                      4|                      1| 29.125|\n",
      "|       1|     2|Mr. Charles Eugen...|  male|23.0|                      0|                      0|   13.0|\n",
      "|       0|     3|Mrs. Julius (Emel...|female|31.0|                      1|                      0|   18.0|\n",
      "|       1|     3|Mrs. Fatima Masse...|female|22.0|                      0|                      0|  7.225|\n",
      "+--------+------+--------------------+------+----+-----------------------+-----------------------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Survived',\n",
       " 'Pclass',\n",
       " 'Name',\n",
       " 'Sex',\n",
       " 'Age',\n",
       " 'Siblings/Spouses Aboard',\n",
       " 'Parents/Children Aboard',\n",
       " 'Fare']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+------------------+\n",
      "|summary|           Survived|               Age|\n",
      "+-------+-------------------+------------------+\n",
      "|  count|                887|               887|\n",
      "|   mean| 0.3855693348365276|29.471443066516347|\n",
      "| stddev|0.48700411775101266|14.121908405462552|\n",
      "|    min|                  0|              0.42|\n",
      "|    max|                  1|              80.0|\n",
      "+-------+-------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.describe(['Survived','Age']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+------------------+\n",
      "|summary|           Survived|               Age|\n",
      "+-------+-------------------+------------------+\n",
      "|  count|                887|               887|\n",
      "|   mean| 0.3855693348365276|29.471443066516347|\n",
      "| stddev|0.48700411775101266|14.121908405462552|\n",
      "|    min|                  0|              0.42|\n",
      "|    max|                  1|              80.0|\n",
      "+-------+-------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df[['Survived','Age']].describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Builder',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__enter__',\n",
       " '__eq__',\n",
       " '__exit__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_convert_from_pandas',\n",
       " '_createFromLocal',\n",
       " '_createFromRDD',\n",
       " '_create_from_pandas_with_arrow',\n",
       " '_create_shell_session',\n",
       " '_get_numpy_record_dtype',\n",
       " '_inferSchema',\n",
       " '_inferSchemaFromList',\n",
       " '_instantiatedSession',\n",
       " '_jsc',\n",
       " '_jsparkSession',\n",
       " '_jvm',\n",
       " '_jwrapped',\n",
       " '_repr_html_',\n",
       " '_sc',\n",
       " '_wrapped',\n",
       " 'builder',\n",
       " 'catalog',\n",
       " 'conf',\n",
       " 'createDataFrame',\n",
       " 'newSession',\n",
       " 'range',\n",
       " 'read',\n",
       " 'readStream',\n",
       " 'sparkContext',\n",
       " 'sql',\n",
       " 'stop',\n",
       " 'streams',\n",
       " 'table',\n",
       " 'udf',\n",
       " 'version']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RDD, Resilient Distributed Dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "nums= sc.parallelize([1,2,3,4])\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nums.take(1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nums.take(3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 \n",
      "4 \n",
      "9 \n",
      "16 \n"
     ]
    }
   ],
   "source": [
    "squared = nums.map(lambda x: x*x).collect()\n",
    "for num in squared:\n",
    "    print('%i ' % (num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  데이터프레임 사용하기 \n",
    "\n",
    "보다 편리한 방법은 DataFrame을 사용하는 것입니다. SparkContext가 이미 설정되어 있으면이를 사용하여 dataFrame을 만들 수 있습니다.\n",
    "\n",
    "또한 SQLContext를 선언해야합니다.\n",
    "\n",
    "SQLContext를 사용하면 엔진을 다른 데이터 소스와 연결할 수 있습니다. Spark SQL의 기능을 시작하는 데 사용됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_p = [('John',19),('Smith',29),('Adam',35),('Henry',50)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "### build rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = sc.parallelize(list_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppl = rdd.map(lambda x: Row(name=x[0], age=int(x[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[25] at RDD at PythonRDD.scala:53"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ppl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Row\n",
    "from pyspark.sql import SQLContext\n",
    "\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_ppl = sqlContext.createDataFrame(ppl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[age: bigint, name: string]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF_ppl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- age: long (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "DF_ppl.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
